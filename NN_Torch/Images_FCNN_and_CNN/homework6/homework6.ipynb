{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claude Shyaka\n",
    "### ID#: 801326243\n",
    "# Homework 6: Fully Connected Neural Nets and Convolution Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x28f1d3cf990>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
    "torch.manual_seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_path = '../data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "\n",
    "transformed_cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.2470, 0.2435, 0.2616))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t, _ = transformed_cifar10[23]\n",
    "type(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 32, 32]), torch.float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t.shape, img_t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using Fully Connected Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import datetime\n",
    "                                         \n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        for imgs, labels in train_loader:\n",
    "            batch_size = imgs.shape[0]\n",
    "            outputs = model(imgs.view(batch_size, -1))\n",
    "            loss = loss_fn(outputs, labels)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch <= 3 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch, loss))\n",
    "\n",
    "def val_loop(model, train_loader, val_loader):\n",
    "    for name, loader in [('train', train_loader), ('val', val_loader)]:\n",
    "        \n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                batch_size = imgs.shape[0]\n",
    "                outputs = model(imgs.view(batch_size, -1))\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "    \n",
    "        print(\"Accuracy {}: {:.2f}\".format(name, correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Fully connected neural net (one hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-11 10:58:13.280757 Epoch 1, Training loss 1.8393231630325317\n",
      "2022-12-11 10:58:30.015504 Epoch 2, Training loss 1.377354621887207\n",
      "2022-12-11 10:58:43.478048 Epoch 3, Training loss 1.9925981760025024\n",
      "2022-12-11 10:59:59.939604 Epoch 10, Training loss 1.0380967855453491\n",
      "2022-12-11 11:01:41.304959 Epoch 20, Training loss 1.15604567527771\n",
      "2022-12-11 11:03:21.026989 Epoch 30, Training loss 0.7549644112586975\n",
      "2022-12-11 11:05:01.675494 Epoch 40, Training loss 0.4356018602848053\n",
      "2022-12-11 11:06:41.957034 Epoch 50, Training loss 0.264767587184906\n",
      "2022-12-11 11:08:22.161326 Epoch 60, Training loss 0.12443574517965317\n",
      "2022-12-11 11:10:01.373402 Epoch 70, Training loss 0.09410518407821655\n",
      "2022-12-11 11:11:42.354460 Epoch 80, Training loss 0.08069346100091934\n",
      "2022-12-11 11:13:23.798328 Epoch 90, Training loss 0.039708103984594345\n",
      "2022-12-11 11:15:04.947798 Epoch 100, Training loss 0.05832041800022125\n",
      "2022-12-11 11:16:45.813132 Epoch 110, Training loss 0.04636174440383911\n",
      "2022-12-11 11:18:26.164265 Epoch 120, Training loss 0.049561962485313416\n",
      "2022-12-11 11:20:07.168203 Epoch 130, Training loss 0.028371520340442657\n",
      "2022-12-11 11:21:47.237991 Epoch 140, Training loss 0.013714182190597057\n",
      "2022-12-11 11:23:26.646798 Epoch 150, Training loss 0.020319394767284393\n",
      "2022-12-11 11:25:08.736029 Epoch 160, Training loss 0.011101871728897095\n",
      "2022-12-11 11:26:49.043395 Epoch 170, Training loss 0.012981481850147247\n",
      "2022-12-11 11:28:29.849446 Epoch 180, Training loss 0.018580114468932152\n",
      "2022-12-11 11:30:11.089260 Epoch 190, Training loss 0.014980962499976158\n",
      "2022-12-11 11:31:50.606455 Epoch 200, Training loss 0.009732008911669254\n",
      "2022-12-11 11:33:37.320776 Epoch 210, Training loss 0.007163901347666979\n",
      "2022-12-11 11:35:16.500358 Epoch 220, Training loss 0.009737375192344189\n",
      "2022-12-11 11:36:56.939044 Epoch 230, Training loss 0.00758917722851038\n",
      "2022-12-11 11:38:36.459644 Epoch 240, Training loss 0.006323343608528376\n",
      "2022-12-11 11:40:15.945743 Epoch 250, Training loss 0.00980254914611578\n",
      "2022-12-11 11:41:55.472943 Epoch 260, Training loss 0.004503951407968998\n",
      "2022-12-11 11:43:35.803643 Epoch 270, Training loss 0.0066040619276463985\n",
      "2022-12-11 11:45:15.804862 Epoch 280, Training loss 0.008188340812921524\n",
      "2022-12-11 11:46:55.771103 Epoch 290, Training loss 0.01005062647163868\n",
      "2022-12-11 11:48:38.092438 Epoch 300, Training loss 0.004050200339406729\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(transformed_cifar10, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "n_out = 10\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, n_out),\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs=300,\n",
    "    optimizer=optimizer,\n",
    "    model=model, \n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 1.00\n",
      "Accuracy val: 0.47\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(transformed_cifar10, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(transformed_cifar10_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "val_loop(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), data_path + 'all_classes_in_cifar10_one_hidden.pt')\n",
    "# loaded_model = model()\n",
    "# loaded_model.load_state_dict(torch.load(data_path+'all_classes_in_cifar10_one_hidden.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully connected neural neural (two hidden layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-11 11:49:02.899913 Epoch 1, Training loss 1.6245378255844116\n",
      "2022-12-11 11:49:19.819966 Epoch 2, Training loss 1.6818033456802368\n",
      "2022-12-11 11:49:37.004989 Epoch 3, Training loss 1.534187912940979\n",
      "2022-12-11 11:51:35.551934 Epoch 10, Training loss 1.4621562957763672\n",
      "2022-12-11 11:54:24.723951 Epoch 20, Training loss 1.0064070224761963\n",
      "2022-12-11 11:57:13.760355 Epoch 30, Training loss 0.42223429679870605\n",
      "2022-12-11 12:00:03.094297 Epoch 40, Training loss 0.07197032868862152\n",
      "2022-12-11 12:02:54.256213 Epoch 50, Training loss 0.1319016069173813\n",
      "2022-12-11 12:05:44.142279 Epoch 60, Training loss 0.022984590381383896\n",
      "2022-12-11 12:08:34.084251 Epoch 70, Training loss 0.0033064864110201597\n",
      "2022-12-11 12:11:24.021114 Epoch 80, Training loss 0.0019372004317119718\n",
      "2022-12-11 12:14:13.798448 Epoch 90, Training loss 0.0008641885360702872\n",
      "2022-12-11 12:17:02.126268 Epoch 100, Training loss 0.0011034191120415926\n",
      "2022-12-11 12:19:52.784060 Epoch 110, Training loss 0.0006099769379943609\n",
      "2022-12-11 12:22:41.074480 Epoch 120, Training loss 0.0008398221689276397\n",
      "2022-12-11 12:25:30.723128 Epoch 130, Training loss 0.0008954134536907077\n",
      "2022-12-11 12:28:21.668476 Epoch 140, Training loss 0.0007451024139299989\n",
      "2022-12-11 12:31:11.834882 Epoch 150, Training loss 0.0005631508538499475\n",
      "2022-12-11 12:34:01.583784 Epoch 160, Training loss 0.0005271332920528948\n",
      "2022-12-11 12:36:50.202954 Epoch 170, Training loss 0.0003790711925830692\n",
      "2022-12-11 12:39:39.443500 Epoch 180, Training loss 0.00025765557074919343\n",
      "2022-12-11 12:42:27.638850 Epoch 190, Training loss 0.0004719950957223773\n",
      "2022-12-11 12:45:16.506408 Epoch 200, Training loss 0.0006778298411518335\n",
      "2022-12-11 12:48:05.959776 Epoch 210, Training loss 0.00048704916844144464\n",
      "2022-12-11 12:50:53.919736 Epoch 220, Training loss 0.0003699174558278173\n",
      "2022-12-11 12:53:47.629453 Epoch 230, Training loss 0.00029789580730721354\n",
      "2022-12-11 12:56:36.433313 Epoch 240, Training loss 0.0004132403992116451\n",
      "2022-12-11 12:59:24.512749 Epoch 250, Training loss 0.0003209938295185566\n",
      "2022-12-11 13:02:12.671812 Epoch 260, Training loss 0.00025040138280019164\n",
      "2022-12-11 13:05:00.841798 Epoch 270, Training loss 0.0002103303122567013\n",
      "2022-12-11 13:07:49.223346 Epoch 280, Training loss 0.00028234851197339594\n",
      "2022-12-11 13:10:37.428494 Epoch 290, Training loss 0.0002949855988845229\n",
      "2022-12-11 13:13:27.077946 Epoch 300, Training loss 0.00021510093938559294\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(transformed_cifar10, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "n_out = 10\n",
    "model = None\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 1024),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(128, 10),\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs=300,\n",
    "    optimizer=optimizer,\n",
    "    model=model, \n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 1.00\n",
      "Accuracy val: 0.47\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(transformed_cifar10, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(transformed_cifar10_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "val_loop(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), data_path + 'all_classes_in_cifar10_two_hidden_nn.pt')\n",
    "# loaded_model = model()\n",
    "# loaded_model.load_state_dict(torch.load(data_path+'all_classes_in_cifar10_two_hidden_nn.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Convolution Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using neural net similar to the one lecture notes but with 10 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "model = Net()\n",
    "# model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cpu.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)  # <1>\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            # print(imgs.shape, outputs.shape)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-11 13:13:52.508301 Epoch 1, Training loss 2.0156423204085407\n",
      "2022-12-11 13:16:05.405889 Epoch 10, Training loss 1.2216555023437266\n",
      "2022-12-11 13:18:33.368723 Epoch 20, Training loss 1.0031733327661938\n",
      "2022-12-11 13:20:59.987900 Epoch 30, Training loss 0.9101834044889416\n",
      "2022-12-11 13:23:27.816641 Epoch 40, Training loss 0.8509914136451223\n",
      "2022-12-11 13:25:54.989934 Epoch 50, Training loss 0.8117253520071049\n",
      "2022-12-11 13:28:21.737352 Epoch 60, Training loss 0.7813487655823798\n",
      "2022-12-11 13:30:48.293637 Epoch 70, Training loss 0.7542348110386173\n",
      "2022-12-11 13:33:15.056108 Epoch 80, Training loss 0.7311401380145032\n",
      "2022-12-11 13:35:41.888631 Epoch 90, Training loss 0.7101649436575678\n",
      "2022-12-11 13:38:08.861524 Epoch 100, Training loss 0.6938671661764765\n",
      "2022-12-11 13:40:35.628594 Epoch 110, Training loss 0.6760904482182335\n",
      "2022-12-11 13:43:03.442203 Epoch 120, Training loss 0.6625848272267509\n",
      "2022-12-11 13:45:30.827530 Epoch 130, Training loss 0.6487830730579088\n",
      "2022-12-11 13:47:58.782459 Epoch 140, Training loss 0.6346335206037897\n",
      "2022-12-11 13:50:25.367372 Epoch 150, Training loss 0.6240607622029531\n",
      "2022-12-11 13:52:51.995629 Epoch 160, Training loss 0.6145861420942389\n",
      "2022-12-11 13:55:18.039775 Epoch 170, Training loss 0.6042480942462106\n",
      "2022-12-11 13:57:44.749598 Epoch 180, Training loss 0.5934932907981336\n",
      "2022-12-11 14:00:11.158989 Epoch 190, Training loss 0.5860818295603822\n",
      "2022-12-11 14:02:38.453734 Epoch 200, Training loss 0.5788571949276473\n",
      "2022-12-11 14:05:04.896224 Epoch 210, Training loss 0.5705193582245761\n",
      "2022-12-11 14:07:31.662349 Epoch 220, Training loss 0.563242406948753\n",
      "2022-12-11 14:09:58.151357 Epoch 230, Training loss 0.5561558144438602\n",
      "2022-12-11 14:12:28.405233 Epoch 240, Training loss 0.5510815901448355\n",
      "2022-12-11 14:14:56.186957 Epoch 250, Training loss 0.5443046591470918\n",
      "2022-12-11 14:17:23.324661 Epoch 260, Training loss 0.5399858901262893\n",
      "2022-12-11 14:19:51.298577 Epoch 270, Training loss 0.5335220971794994\n",
      "2022-12-11 14:22:18.442372 Epoch 280, Training loss 0.5296325752954654\n",
      "2022-12-11 14:24:45.854437 Epoch 290, Training loss 0.5260840745266441\n",
      "2022-12-11 14:27:13.134569 Epoch 300, Training loss 0.5220733637661885\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(transformed_cifar10, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = Net().to(device=device)  # <1>\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 300,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.82\n",
      "Accuracy val: 0.61\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(transformed_cifar10, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(transformed_cifar10_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "all_acc_dict = collections.OrderedDict()\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    accdict = {}\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <1>\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        accdict[name] = correct / total\n",
    "    return accdict\n",
    "\n",
    "all_acc_dict[\"baseline\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), data_path + 'all_classes_in_cifar10_cnn_base.pt')\n",
    "# loaded_model = Net().to(device=device)\n",
    "# loaded_model.load_state_dict(torch.load(data_path\n",
    "#                                         + 'all_classes_in_cifar10_cnn_base.pt',\n",
    "#                                         map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 16, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        # self.fc3 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv3(out)), 2)\n",
    "        out = out.view(-1, 16 * 4 * 4)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        # out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "model = Net1()\n",
    "# model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-11 14:28:09.150179 Epoch 1, Training loss 2.064853612114401\n",
      "2022-12-11 14:34:37.674423 Epoch 10, Training loss 1.1025405135910835\n",
      "2022-12-11 14:41:55.699034 Epoch 20, Training loss 0.8562657746207684\n",
      "2022-12-11 14:49:07.887266 Epoch 30, Training loss 0.7458662279807698\n",
      "2022-12-11 14:56:17.773746 Epoch 40, Training loss 0.6705487764171322\n",
      "2022-12-11 15:03:27.162519 Epoch 50, Training loss 0.6126089401333533\n",
      "2022-12-11 15:10:36.274668 Epoch 60, Training loss 0.5626459585888611\n",
      "2022-12-11 15:17:46.295135 Epoch 70, Training loss 0.515264455276682\n",
      "2022-12-11 15:24:57.113478 Epoch 80, Training loss 0.4724246436525184\n",
      "2022-12-11 15:32:08.335192 Epoch 90, Training loss 0.4301049930169759\n",
      "2022-12-11 15:39:24.092985 Epoch 100, Training loss 0.3899847258958975\n",
      "2022-12-11 15:46:38.435604 Epoch 110, Training loss 0.3535082617112438\n",
      "2022-12-11 15:53:51.594794 Epoch 120, Training loss 0.3165793933279222\n",
      "2022-12-11 16:01:13.121350 Epoch 130, Training loss 0.2819230659481357\n",
      "2022-12-11 16:08:35.954663 Epoch 140, Training loss 0.24953677168930583\n",
      "2022-12-11 16:15:58.499080 Epoch 150, Training loss 0.21859648085349356\n",
      "2022-12-11 16:40:40.358212 Epoch 160, Training loss 0.18969233474120153\n",
      "2022-12-11 16:47:55.770435 Epoch 170, Training loss 0.1623769300796873\n",
      "2022-12-11 16:55:03.812128 Epoch 180, Training loss 0.1382157504939667\n",
      "2022-12-11 17:02:12.379850 Epoch 190, Training loss 0.11878147475954974\n",
      "2022-12-11 17:09:20.858388 Epoch 200, Training loss 0.10004898622546278\n",
      "2022-12-11 17:16:34.165382 Epoch 210, Training loss 0.08254442197006301\n",
      "2022-12-11 17:23:43.866635 Epoch 220, Training loss 0.0679532005749357\n",
      "2022-12-11 17:30:53.883176 Epoch 230, Training loss 0.05754269234588384\n",
      "2022-12-11 17:38:03.447171 Epoch 240, Training loss 0.04721187149434138\n",
      "2022-12-11 17:45:13.711150 Epoch 250, Training loss 0.039008031913634306\n",
      "2022-12-11 17:52:23.181251 Epoch 260, Training loss 0.03391805781489786\n",
      "2022-12-11 17:59:32.453462 Epoch 270, Training loss 0.028365046483800387\n",
      "2022-12-11 18:06:42.156427 Epoch 280, Training loss 0.024700839759048333\n",
      "2022-12-11 18:13:51.625063 Epoch 290, Training loss 0.021478109199868138\n",
      "2022-12-11 18:21:03.999532 Epoch 300, Training loss 0.019198353471391646\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(transformed_cifar10, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = Net1().to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 300,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 1.00\n",
      "Accuracy val: 0.70\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(transformed_cifar10, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(transformed_cifar10_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "all_acc_dict = collections.OrderedDict()\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    accdict = {}\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <1>\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        accdict[name] = correct / total\n",
    "    return accdict\n",
    "\n",
    "all_acc_dict[\"baseline\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), data_path + 'all_classes_in_cifar10_cnn_extented.pt')\n",
    "# loaded_model = Net().to(device=device)\n",
    "# loaded_model.load_state_dict(torch.load(data_path\n",
    "#                                         + 'all_classes_in_cifar10_cnn_base.pt',\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "bceacc533795745525e6bab599580a5ca9d32e982a9d1a436f49660b5b14ade2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
